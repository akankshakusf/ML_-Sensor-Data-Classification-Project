{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Akanksha Kushwaha U95902810"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will focus on sensor data. The dataset contains accelerometer data from cell phones. Accelerometer helps measure the speed and acceleration of a cell phone's movement. Each row represents a single measurement (captured on a timeline). There are a total of 20 time steps (columns). This is a multiclass classification task: predict what type of transportation each measurement (i.e., row) represents based on the accelerometer data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of Variables\n",
    "\n",
    "You will use the **movement.csv** data set for this assignment. Each row represents a single measurement. Columns labeled as 1 from 20 are the time steps on the timeline (there are 20 time steps, each time step has only one measurement). \n",
    "\n",
    "The last column is the target variable. It shows the label (category) of the measurement. Because it is a text-based column, **it must be converted to ordinal values.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "Use the data set **movement.csv** to predict the column called **Target**. The input variables are columns labeled as **1 to 20**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission:\n",
    "\n",
    "Please save and submit this Jupyter notebook file. The correctness of the code matters for your grade. **Readability and organization of your code is also important.** You may lose points for submitting unreadable/undecipherable code. Therefore, use markdown cells to create sections, and use comments where necessary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Prepare the Data (1 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\akush\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"movement.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118, 21)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.179784</td>\n",
       "      <td>1.179784</td>\n",
       "      <td>0.810629</td>\n",
       "      <td>0.810629</td>\n",
       "      <td>1.041816</td>\n",
       "      <td>1.041816</td>\n",
       "      <td>1.041816</td>\n",
       "      <td>0.453604</td>\n",
       "      <td>0.453604</td>\n",
       "      <td>0.483920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250571</td>\n",
       "      <td>0.250571</td>\n",
       "      <td>0.250571</td>\n",
       "      <td>0.250571</td>\n",
       "      <td>0.250571</td>\n",
       "      <td>0.250571</td>\n",
       "      <td>0.167502</td>\n",
       "      <td>0.167502</td>\n",
       "      <td>0.167502</td>\n",
       "      <td>Bus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.115912</td>\n",
       "      <td>0.860983</td>\n",
       "      <td>0.860983</td>\n",
       "      <td>0.860983</td>\n",
       "      <td>0.860983</td>\n",
       "      <td>1.020423</td>\n",
       "      <td>1.020423</td>\n",
       "      <td>1.333723</td>\n",
       "      <td>1.333723</td>\n",
       "      <td>1.333723</td>\n",
       "      <td>...</td>\n",
       "      <td>1.582763</td>\n",
       "      <td>0.936744</td>\n",
       "      <td>0.936744</td>\n",
       "      <td>0.936744</td>\n",
       "      <td>0.936744</td>\n",
       "      <td>1.412754</td>\n",
       "      <td>3.283429</td>\n",
       "      <td>3.283429</td>\n",
       "      <td>3.283429</td>\n",
       "      <td>Bus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.572300</td>\n",
       "      <td>0.147040</td>\n",
       "      <td>0.147040</td>\n",
       "      <td>0.147040</td>\n",
       "      <td>0.147040</td>\n",
       "      <td>0.147040</td>\n",
       "      <td>0.147040</td>\n",
       "      <td>0.147040</td>\n",
       "      <td>0.147040</td>\n",
       "      <td>2.662993</td>\n",
       "      <td>...</td>\n",
       "      <td>2.662993</td>\n",
       "      <td>2.662993</td>\n",
       "      <td>2.662993</td>\n",
       "      <td>1.449779</td>\n",
       "      <td>1.449779</td>\n",
       "      <td>1.147295</td>\n",
       "      <td>0.978355</td>\n",
       "      <td>0.978355</td>\n",
       "      <td>0.978355</td>\n",
       "      <td>Bus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.128633</td>\n",
       "      <td>1.128633</td>\n",
       "      <td>1.128633</td>\n",
       "      <td>1.128633</td>\n",
       "      <td>1.128633</td>\n",
       "      <td>3.181596</td>\n",
       "      <td>4.012386</td>\n",
       "      <td>4.012386</td>\n",
       "      <td>1.349989</td>\n",
       "      <td>1.266019</td>\n",
       "      <td>...</td>\n",
       "      <td>1.266019</td>\n",
       "      <td>1.266019</td>\n",
       "      <td>0.492464</td>\n",
       "      <td>0.710132</td>\n",
       "      <td>0.710132</td>\n",
       "      <td>0.251398</td>\n",
       "      <td>0.251398</td>\n",
       "      <td>1.347456</td>\n",
       "      <td>1.347456</td>\n",
       "      <td>Bus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.548065</td>\n",
       "      <td>0.548065</td>\n",
       "      <td>0.548065</td>\n",
       "      <td>1.441688</td>\n",
       "      <td>0.631261</td>\n",
       "      <td>0.631261</td>\n",
       "      <td>0.631261</td>\n",
       "      <td>9.258070</td>\n",
       "      <td>1.495908</td>\n",
       "      <td>0.723835</td>\n",
       "      <td>...</td>\n",
       "      <td>8.073005</td>\n",
       "      <td>8.073005</td>\n",
       "      <td>8.073005</td>\n",
       "      <td>8.073005</td>\n",
       "      <td>1.124158</td>\n",
       "      <td>0.399042</td>\n",
       "      <td>0.399042</td>\n",
       "      <td>0.399042</td>\n",
       "      <td>0.561521</td>\n",
       "      <td>Car</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5         6         7  \\\n",
       "0  1.179784  1.179784  0.810629  0.810629  1.041816  1.041816  1.041816   \n",
       "1  1.115912  0.860983  0.860983  0.860983  0.860983  1.020423  1.020423   \n",
       "2  0.572300  0.147040  0.147040  0.147040  0.147040  0.147040  0.147040   \n",
       "3  1.128633  1.128633  1.128633  1.128633  1.128633  3.181596  4.012386   \n",
       "4  0.548065  0.548065  0.548065  1.441688  0.631261  0.631261  0.631261   \n",
       "\n",
       "          8         9        10  ...        12        13        14        15  \\\n",
       "0  0.453604  0.453604  0.483920  ...  0.250571  0.250571  0.250571  0.250571   \n",
       "1  1.333723  1.333723  1.333723  ...  1.582763  0.936744  0.936744  0.936744   \n",
       "2  0.147040  0.147040  2.662993  ...  2.662993  2.662993  2.662993  1.449779   \n",
       "3  4.012386  1.349989  1.266019  ...  1.266019  1.266019  0.492464  0.710132   \n",
       "4  9.258070  1.495908  0.723835  ...  8.073005  8.073005  8.073005  8.073005   \n",
       "\n",
       "         16        17        18        19        20  Target  \n",
       "0  0.250571  0.250571  0.167502  0.167502  0.167502     Bus  \n",
       "1  0.936744  1.412754  3.283429  3.283429  3.283429     Bus  \n",
       "2  1.449779  1.147295  0.978355  0.978355  0.978355     Bus  \n",
       "3  0.710132  0.251398  0.251398  1.347456  1.347456     Bus  \n",
       "4  1.124158  0.399042  0.399042  0.399042  0.561521     Car  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding an Ordinal Field based on Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the order of categories explicitly for the OrdinalEncoder\n",
    "categories_order = [['Still', 'Walking', 'Bus', 'Car', 'Train']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Initialize the OrdinalEncoder with the specified categories order\n",
    "encoder = OrdinalEncoder(categories=categories_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the 'Target' column, then add a new 'target_ordinal' field in the DataFrame\n",
    "data['target_ordinal'] = encoder.fit_transform(data[['Target']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>Target</th>\n",
       "      <th>target_ordinal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.179784</td>\n",
       "      <td>1.179784</td>\n",
       "      <td>0.810629</td>\n",
       "      <td>0.810629</td>\n",
       "      <td>1.041816</td>\n",
       "      <td>1.041816</td>\n",
       "      <td>1.041816</td>\n",
       "      <td>0.453604</td>\n",
       "      <td>0.453604</td>\n",
       "      <td>0.483920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250571</td>\n",
       "      <td>0.250571</td>\n",
       "      <td>0.250571</td>\n",
       "      <td>0.250571</td>\n",
       "      <td>0.250571</td>\n",
       "      <td>0.167502</td>\n",
       "      <td>0.167502</td>\n",
       "      <td>0.167502</td>\n",
       "      <td>Bus</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.115912</td>\n",
       "      <td>0.860983</td>\n",
       "      <td>0.860983</td>\n",
       "      <td>0.860983</td>\n",
       "      <td>0.860983</td>\n",
       "      <td>1.020423</td>\n",
       "      <td>1.020423</td>\n",
       "      <td>1.333723</td>\n",
       "      <td>1.333723</td>\n",
       "      <td>1.333723</td>\n",
       "      <td>...</td>\n",
       "      <td>0.936744</td>\n",
       "      <td>0.936744</td>\n",
       "      <td>0.936744</td>\n",
       "      <td>0.936744</td>\n",
       "      <td>1.412754</td>\n",
       "      <td>3.283429</td>\n",
       "      <td>3.283429</td>\n",
       "      <td>3.283429</td>\n",
       "      <td>Bus</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.572300</td>\n",
       "      <td>0.147040</td>\n",
       "      <td>0.147040</td>\n",
       "      <td>0.147040</td>\n",
       "      <td>0.147040</td>\n",
       "      <td>0.147040</td>\n",
       "      <td>0.147040</td>\n",
       "      <td>0.147040</td>\n",
       "      <td>0.147040</td>\n",
       "      <td>2.662993</td>\n",
       "      <td>...</td>\n",
       "      <td>2.662993</td>\n",
       "      <td>2.662993</td>\n",
       "      <td>1.449779</td>\n",
       "      <td>1.449779</td>\n",
       "      <td>1.147295</td>\n",
       "      <td>0.978355</td>\n",
       "      <td>0.978355</td>\n",
       "      <td>0.978355</td>\n",
       "      <td>Bus</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.128633</td>\n",
       "      <td>1.128633</td>\n",
       "      <td>1.128633</td>\n",
       "      <td>1.128633</td>\n",
       "      <td>1.128633</td>\n",
       "      <td>3.181596</td>\n",
       "      <td>4.012386</td>\n",
       "      <td>4.012386</td>\n",
       "      <td>1.349989</td>\n",
       "      <td>1.266019</td>\n",
       "      <td>...</td>\n",
       "      <td>1.266019</td>\n",
       "      <td>0.492464</td>\n",
       "      <td>0.710132</td>\n",
       "      <td>0.710132</td>\n",
       "      <td>0.251398</td>\n",
       "      <td>0.251398</td>\n",
       "      <td>1.347456</td>\n",
       "      <td>1.347456</td>\n",
       "      <td>Bus</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.548065</td>\n",
       "      <td>0.548065</td>\n",
       "      <td>0.548065</td>\n",
       "      <td>1.441688</td>\n",
       "      <td>0.631261</td>\n",
       "      <td>0.631261</td>\n",
       "      <td>0.631261</td>\n",
       "      <td>9.258070</td>\n",
       "      <td>1.495908</td>\n",
       "      <td>0.723835</td>\n",
       "      <td>...</td>\n",
       "      <td>8.073005</td>\n",
       "      <td>8.073005</td>\n",
       "      <td>8.073005</td>\n",
       "      <td>1.124158</td>\n",
       "      <td>0.399042</td>\n",
       "      <td>0.399042</td>\n",
       "      <td>0.399042</td>\n",
       "      <td>0.561521</td>\n",
       "      <td>Car</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5         6         7  \\\n",
       "0  1.179784  1.179784  0.810629  0.810629  1.041816  1.041816  1.041816   \n",
       "1  1.115912  0.860983  0.860983  0.860983  0.860983  1.020423  1.020423   \n",
       "2  0.572300  0.147040  0.147040  0.147040  0.147040  0.147040  0.147040   \n",
       "3  1.128633  1.128633  1.128633  1.128633  1.128633  3.181596  4.012386   \n",
       "4  0.548065  0.548065  0.548065  1.441688  0.631261  0.631261  0.631261   \n",
       "\n",
       "          8         9        10  ...        13        14        15        16  \\\n",
       "0  0.453604  0.453604  0.483920  ...  0.250571  0.250571  0.250571  0.250571   \n",
       "1  1.333723  1.333723  1.333723  ...  0.936744  0.936744  0.936744  0.936744   \n",
       "2  0.147040  0.147040  2.662993  ...  2.662993  2.662993  1.449779  1.449779   \n",
       "3  4.012386  1.349989  1.266019  ...  1.266019  0.492464  0.710132  0.710132   \n",
       "4  9.258070  1.495908  0.723835  ...  8.073005  8.073005  8.073005  1.124158   \n",
       "\n",
       "         17        18        19        20  Target  target_ordinal  \n",
       "0  0.250571  0.167502  0.167502  0.167502     Bus             2.0  \n",
       "1  1.412754  3.283429  3.283429  3.283429     Bus             2.0  \n",
       "2  1.147295  0.978355  0.978355  0.978355     Bus             2.0  \n",
       "3  0.251398  0.251398  1.347456  1.347456     Bus             2.0  \n",
       "4  0.399042  0.399042  0.399042  0.561521     Car             3.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the updated DataFrame\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>Target</th>\n",
       "      <th>target_ordinal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.179784</td>\n",
       "      <td>1.179784</td>\n",
       "      <td>0.810629</td>\n",
       "      <td>0.810629</td>\n",
       "      <td>1.041816</td>\n",
       "      <td>1.041816</td>\n",
       "      <td>1.041816</td>\n",
       "      <td>0.453604</td>\n",
       "      <td>0.453604</td>\n",
       "      <td>0.483920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250571</td>\n",
       "      <td>0.250571</td>\n",
       "      <td>0.250571</td>\n",
       "      <td>0.250571</td>\n",
       "      <td>0.250571</td>\n",
       "      <td>0.167502</td>\n",
       "      <td>0.167502</td>\n",
       "      <td>0.167502</td>\n",
       "      <td>Bus</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.115912</td>\n",
       "      <td>0.860983</td>\n",
       "      <td>0.860983</td>\n",
       "      <td>0.860983</td>\n",
       "      <td>0.860983</td>\n",
       "      <td>1.020423</td>\n",
       "      <td>1.020423</td>\n",
       "      <td>1.333723</td>\n",
       "      <td>1.333723</td>\n",
       "      <td>1.333723</td>\n",
       "      <td>...</td>\n",
       "      <td>0.936744</td>\n",
       "      <td>0.936744</td>\n",
       "      <td>0.936744</td>\n",
       "      <td>0.936744</td>\n",
       "      <td>1.412754</td>\n",
       "      <td>3.283429</td>\n",
       "      <td>3.283429</td>\n",
       "      <td>3.283429</td>\n",
       "      <td>Bus</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.572300</td>\n",
       "      <td>0.147040</td>\n",
       "      <td>0.147040</td>\n",
       "      <td>0.147040</td>\n",
       "      <td>0.147040</td>\n",
       "      <td>0.147040</td>\n",
       "      <td>0.147040</td>\n",
       "      <td>0.147040</td>\n",
       "      <td>0.147040</td>\n",
       "      <td>2.662993</td>\n",
       "      <td>...</td>\n",
       "      <td>2.662993</td>\n",
       "      <td>2.662993</td>\n",
       "      <td>1.449779</td>\n",
       "      <td>1.449779</td>\n",
       "      <td>1.147295</td>\n",
       "      <td>0.978355</td>\n",
       "      <td>0.978355</td>\n",
       "      <td>0.978355</td>\n",
       "      <td>Bus</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.128633</td>\n",
       "      <td>1.128633</td>\n",
       "      <td>1.128633</td>\n",
       "      <td>1.128633</td>\n",
       "      <td>1.128633</td>\n",
       "      <td>3.181596</td>\n",
       "      <td>4.012386</td>\n",
       "      <td>4.012386</td>\n",
       "      <td>1.349989</td>\n",
       "      <td>1.266019</td>\n",
       "      <td>...</td>\n",
       "      <td>1.266019</td>\n",
       "      <td>0.492464</td>\n",
       "      <td>0.710132</td>\n",
       "      <td>0.710132</td>\n",
       "      <td>0.251398</td>\n",
       "      <td>0.251398</td>\n",
       "      <td>1.347456</td>\n",
       "      <td>1.347456</td>\n",
       "      <td>Bus</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.548065</td>\n",
       "      <td>0.548065</td>\n",
       "      <td>0.548065</td>\n",
       "      <td>1.441688</td>\n",
       "      <td>0.631261</td>\n",
       "      <td>0.631261</td>\n",
       "      <td>0.631261</td>\n",
       "      <td>9.258070</td>\n",
       "      <td>1.495908</td>\n",
       "      <td>0.723835</td>\n",
       "      <td>...</td>\n",
       "      <td>8.073005</td>\n",
       "      <td>8.073005</td>\n",
       "      <td>8.073005</td>\n",
       "      <td>1.124158</td>\n",
       "      <td>0.399042</td>\n",
       "      <td>0.399042</td>\n",
       "      <td>0.399042</td>\n",
       "      <td>0.561521</td>\n",
       "      <td>Car</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>1.346025</td>\n",
       "      <td>1.346025</td>\n",
       "      <td>1.346025</td>\n",
       "      <td>2.004300</td>\n",
       "      <td>2.004300</td>\n",
       "      <td>2.004300</td>\n",
       "      <td>4.521426</td>\n",
       "      <td>8.587040</td>\n",
       "      <td>8.587040</td>\n",
       "      <td>13.449106</td>\n",
       "      <td>...</td>\n",
       "      <td>2.669237</td>\n",
       "      <td>6.306398</td>\n",
       "      <td>6.306398</td>\n",
       "      <td>6.306398</td>\n",
       "      <td>2.023114</td>\n",
       "      <td>2.023114</td>\n",
       "      <td>2.023114</td>\n",
       "      <td>4.570821</td>\n",
       "      <td>Walking</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2.863282</td>\n",
       "      <td>0.035689</td>\n",
       "      <td>0.050935</td>\n",
       "      <td>0.780319</td>\n",
       "      <td>1.042465</td>\n",
       "      <td>0.838782</td>\n",
       "      <td>0.387164</td>\n",
       "      <td>0.397090</td>\n",
       "      <td>0.599418</td>\n",
       "      <td>0.419741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370313</td>\n",
       "      <td>0.279862</td>\n",
       "      <td>0.514111</td>\n",
       "      <td>0.849760</td>\n",
       "      <td>0.806333</td>\n",
       "      <td>0.423010</td>\n",
       "      <td>0.708934</td>\n",
       "      <td>0.659056</td>\n",
       "      <td>Car</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2.398008</td>\n",
       "      <td>0.970365</td>\n",
       "      <td>0.906882</td>\n",
       "      <td>2.253443</td>\n",
       "      <td>0.757264</td>\n",
       "      <td>0.965530</td>\n",
       "      <td>0.677990</td>\n",
       "      <td>0.638683</td>\n",
       "      <td>0.661952</td>\n",
       "      <td>1.726219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.611374</td>\n",
       "      <td>0.575126</td>\n",
       "      <td>0.686191</td>\n",
       "      <td>0.793346</td>\n",
       "      <td>1.088155</td>\n",
       "      <td>0.467430</td>\n",
       "      <td>0.712183</td>\n",
       "      <td>1.889786</td>\n",
       "      <td>Car</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.557391</td>\n",
       "      <td>0.557391</td>\n",
       "      <td>0.557391</td>\n",
       "      <td>1.452623</td>\n",
       "      <td>1.452623</td>\n",
       "      <td>1.583060</td>\n",
       "      <td>1.410292</td>\n",
       "      <td>1.410292</td>\n",
       "      <td>1.410292</td>\n",
       "      <td>0.270289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270289</td>\n",
       "      <td>0.270289</td>\n",
       "      <td>0.270289</td>\n",
       "      <td>0.376195</td>\n",
       "      <td>0.376195</td>\n",
       "      <td>0.337485</td>\n",
       "      <td>0.439030</td>\n",
       "      <td>0.582806</td>\n",
       "      <td>Car</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.821967</td>\n",
       "      <td>1.219186</td>\n",
       "      <td>1.219186</td>\n",
       "      <td>0.546986</td>\n",
       "      <td>0.546986</td>\n",
       "      <td>0.546986</td>\n",
       "      <td>0.546986</td>\n",
       "      <td>0.546986</td>\n",
       "      <td>1.347748</td>\n",
       "      <td>1.347748</td>\n",
       "      <td>...</td>\n",
       "      <td>1.347748</td>\n",
       "      <td>1.347748</td>\n",
       "      <td>1.347748</td>\n",
       "      <td>0.168647</td>\n",
       "      <td>0.168647</td>\n",
       "      <td>0.168647</td>\n",
       "      <td>0.168647</td>\n",
       "      <td>0.168647</td>\n",
       "      <td>Car</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            1         2         3         4         5         6         7  \\\n",
       "0    1.179784  1.179784  0.810629  0.810629  1.041816  1.041816  1.041816   \n",
       "1    1.115912  0.860983  0.860983  0.860983  0.860983  1.020423  1.020423   \n",
       "2    0.572300  0.147040  0.147040  0.147040  0.147040  0.147040  0.147040   \n",
       "3    1.128633  1.128633  1.128633  1.128633  1.128633  3.181596  4.012386   \n",
       "4    0.548065  0.548065  0.548065  1.441688  0.631261  0.631261  0.631261   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "113  1.346025  1.346025  1.346025  2.004300  2.004300  2.004300  4.521426   \n",
       "114  2.863282  0.035689  0.050935  0.780319  1.042465  0.838782  0.387164   \n",
       "115  2.398008  0.970365  0.906882  2.253443  0.757264  0.965530  0.677990   \n",
       "116  0.557391  0.557391  0.557391  1.452623  1.452623  1.583060  1.410292   \n",
       "117  0.821967  1.219186  1.219186  0.546986  0.546986  0.546986  0.546986   \n",
       "\n",
       "            8         9         10  ...        13        14        15  \\\n",
       "0    0.453604  0.453604   0.483920  ...  0.250571  0.250571  0.250571   \n",
       "1    1.333723  1.333723   1.333723  ...  0.936744  0.936744  0.936744   \n",
       "2    0.147040  0.147040   2.662993  ...  2.662993  2.662993  1.449779   \n",
       "3    4.012386  1.349989   1.266019  ...  1.266019  0.492464  0.710132   \n",
       "4    9.258070  1.495908   0.723835  ...  8.073005  8.073005  8.073005   \n",
       "..        ...       ...        ...  ...       ...       ...       ...   \n",
       "113  8.587040  8.587040  13.449106  ...  2.669237  6.306398  6.306398   \n",
       "114  0.397090  0.599418   0.419741  ...  0.370313  0.279862  0.514111   \n",
       "115  0.638683  0.661952   1.726219  ...  0.611374  0.575126  0.686191   \n",
       "116  1.410292  1.410292   0.270289  ...  0.270289  0.270289  0.270289   \n",
       "117  0.546986  1.347748   1.347748  ...  1.347748  1.347748  1.347748   \n",
       "\n",
       "           16        17        18        19        20   Target  target_ordinal  \n",
       "0    0.250571  0.250571  0.167502  0.167502  0.167502      Bus             2.0  \n",
       "1    0.936744  1.412754  3.283429  3.283429  3.283429      Bus             2.0  \n",
       "2    1.449779  1.147295  0.978355  0.978355  0.978355      Bus             2.0  \n",
       "3    0.710132  0.251398  0.251398  1.347456  1.347456      Bus             2.0  \n",
       "4    1.124158  0.399042  0.399042  0.399042  0.561521      Car             3.0  \n",
       "..        ...       ...       ...       ...       ...      ...             ...  \n",
       "113  6.306398  2.023114  2.023114  2.023114  4.570821  Walking             1.0  \n",
       "114  0.849760  0.806333  0.423010  0.708934  0.659056      Car             3.0  \n",
       "115  0.793346  1.088155  0.467430  0.712183  1.889786      Car             3.0  \n",
       "116  0.376195  0.376195  0.337485  0.439030  0.582806      Car             3.0  \n",
       "117  0.168647  0.168647  0.168647  0.168647  0.168647      Car             3.0  \n",
       "\n",
       "[118 rows x 22 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can't use the Target columns here \n",
    "\n",
    "main_dataset= data.drop(['Target'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>target_ordinal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.179784</td>\n",
       "      <td>1.179784</td>\n",
       "      <td>0.810629</td>\n",
       "      <td>0.810629</td>\n",
       "      <td>1.041816</td>\n",
       "      <td>1.041816</td>\n",
       "      <td>1.041816</td>\n",
       "      <td>0.453604</td>\n",
       "      <td>0.453604</td>\n",
       "      <td>0.483920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250571</td>\n",
       "      <td>0.250571</td>\n",
       "      <td>0.250571</td>\n",
       "      <td>0.250571</td>\n",
       "      <td>0.250571</td>\n",
       "      <td>0.250571</td>\n",
       "      <td>0.167502</td>\n",
       "      <td>0.167502</td>\n",
       "      <td>0.167502</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.115912</td>\n",
       "      <td>0.860983</td>\n",
       "      <td>0.860983</td>\n",
       "      <td>0.860983</td>\n",
       "      <td>0.860983</td>\n",
       "      <td>1.020423</td>\n",
       "      <td>1.020423</td>\n",
       "      <td>1.333723</td>\n",
       "      <td>1.333723</td>\n",
       "      <td>1.333723</td>\n",
       "      <td>...</td>\n",
       "      <td>1.582763</td>\n",
       "      <td>0.936744</td>\n",
       "      <td>0.936744</td>\n",
       "      <td>0.936744</td>\n",
       "      <td>0.936744</td>\n",
       "      <td>1.412754</td>\n",
       "      <td>3.283429</td>\n",
       "      <td>3.283429</td>\n",
       "      <td>3.283429</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.572300</td>\n",
       "      <td>0.147040</td>\n",
       "      <td>0.147040</td>\n",
       "      <td>0.147040</td>\n",
       "      <td>0.147040</td>\n",
       "      <td>0.147040</td>\n",
       "      <td>0.147040</td>\n",
       "      <td>0.147040</td>\n",
       "      <td>0.147040</td>\n",
       "      <td>2.662993</td>\n",
       "      <td>...</td>\n",
       "      <td>2.662993</td>\n",
       "      <td>2.662993</td>\n",
       "      <td>2.662993</td>\n",
       "      <td>1.449779</td>\n",
       "      <td>1.449779</td>\n",
       "      <td>1.147295</td>\n",
       "      <td>0.978355</td>\n",
       "      <td>0.978355</td>\n",
       "      <td>0.978355</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.128633</td>\n",
       "      <td>1.128633</td>\n",
       "      <td>1.128633</td>\n",
       "      <td>1.128633</td>\n",
       "      <td>1.128633</td>\n",
       "      <td>3.181596</td>\n",
       "      <td>4.012386</td>\n",
       "      <td>4.012386</td>\n",
       "      <td>1.349989</td>\n",
       "      <td>1.266019</td>\n",
       "      <td>...</td>\n",
       "      <td>1.266019</td>\n",
       "      <td>1.266019</td>\n",
       "      <td>0.492464</td>\n",
       "      <td>0.710132</td>\n",
       "      <td>0.710132</td>\n",
       "      <td>0.251398</td>\n",
       "      <td>0.251398</td>\n",
       "      <td>1.347456</td>\n",
       "      <td>1.347456</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.548065</td>\n",
       "      <td>0.548065</td>\n",
       "      <td>0.548065</td>\n",
       "      <td>1.441688</td>\n",
       "      <td>0.631261</td>\n",
       "      <td>0.631261</td>\n",
       "      <td>0.631261</td>\n",
       "      <td>9.258070</td>\n",
       "      <td>1.495908</td>\n",
       "      <td>0.723835</td>\n",
       "      <td>...</td>\n",
       "      <td>8.073005</td>\n",
       "      <td>8.073005</td>\n",
       "      <td>8.073005</td>\n",
       "      <td>8.073005</td>\n",
       "      <td>1.124158</td>\n",
       "      <td>0.399042</td>\n",
       "      <td>0.399042</td>\n",
       "      <td>0.399042</td>\n",
       "      <td>0.561521</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>1.346025</td>\n",
       "      <td>1.346025</td>\n",
       "      <td>1.346025</td>\n",
       "      <td>2.004300</td>\n",
       "      <td>2.004300</td>\n",
       "      <td>2.004300</td>\n",
       "      <td>4.521426</td>\n",
       "      <td>8.587040</td>\n",
       "      <td>8.587040</td>\n",
       "      <td>13.449106</td>\n",
       "      <td>...</td>\n",
       "      <td>2.669237</td>\n",
       "      <td>2.669237</td>\n",
       "      <td>6.306398</td>\n",
       "      <td>6.306398</td>\n",
       "      <td>6.306398</td>\n",
       "      <td>2.023114</td>\n",
       "      <td>2.023114</td>\n",
       "      <td>2.023114</td>\n",
       "      <td>4.570821</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2.863282</td>\n",
       "      <td>0.035689</td>\n",
       "      <td>0.050935</td>\n",
       "      <td>0.780319</td>\n",
       "      <td>1.042465</td>\n",
       "      <td>0.838782</td>\n",
       "      <td>0.387164</td>\n",
       "      <td>0.397090</td>\n",
       "      <td>0.599418</td>\n",
       "      <td>0.419741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.426764</td>\n",
       "      <td>0.370313</td>\n",
       "      <td>0.279862</td>\n",
       "      <td>0.514111</td>\n",
       "      <td>0.849760</td>\n",
       "      <td>0.806333</td>\n",
       "      <td>0.423010</td>\n",
       "      <td>0.708934</td>\n",
       "      <td>0.659056</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2.398008</td>\n",
       "      <td>0.970365</td>\n",
       "      <td>0.906882</td>\n",
       "      <td>2.253443</td>\n",
       "      <td>0.757264</td>\n",
       "      <td>0.965530</td>\n",
       "      <td>0.677990</td>\n",
       "      <td>0.638683</td>\n",
       "      <td>0.661952</td>\n",
       "      <td>1.726219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.945944</td>\n",
       "      <td>0.611374</td>\n",
       "      <td>0.575126</td>\n",
       "      <td>0.686191</td>\n",
       "      <td>0.793346</td>\n",
       "      <td>1.088155</td>\n",
       "      <td>0.467430</td>\n",
       "      <td>0.712183</td>\n",
       "      <td>1.889786</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.557391</td>\n",
       "      <td>0.557391</td>\n",
       "      <td>0.557391</td>\n",
       "      <td>1.452623</td>\n",
       "      <td>1.452623</td>\n",
       "      <td>1.583060</td>\n",
       "      <td>1.410292</td>\n",
       "      <td>1.410292</td>\n",
       "      <td>1.410292</td>\n",
       "      <td>0.270289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270289</td>\n",
       "      <td>0.270289</td>\n",
       "      <td>0.270289</td>\n",
       "      <td>0.270289</td>\n",
       "      <td>0.376195</td>\n",
       "      <td>0.376195</td>\n",
       "      <td>0.337485</td>\n",
       "      <td>0.439030</td>\n",
       "      <td>0.582806</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.821967</td>\n",
       "      <td>1.219186</td>\n",
       "      <td>1.219186</td>\n",
       "      <td>0.546986</td>\n",
       "      <td>0.546986</td>\n",
       "      <td>0.546986</td>\n",
       "      <td>0.546986</td>\n",
       "      <td>0.546986</td>\n",
       "      <td>1.347748</td>\n",
       "      <td>1.347748</td>\n",
       "      <td>...</td>\n",
       "      <td>1.347748</td>\n",
       "      <td>1.347748</td>\n",
       "      <td>1.347748</td>\n",
       "      <td>1.347748</td>\n",
       "      <td>0.168647</td>\n",
       "      <td>0.168647</td>\n",
       "      <td>0.168647</td>\n",
       "      <td>0.168647</td>\n",
       "      <td>0.168647</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            1         2         3         4         5         6         7  \\\n",
       "0    1.179784  1.179784  0.810629  0.810629  1.041816  1.041816  1.041816   \n",
       "1    1.115912  0.860983  0.860983  0.860983  0.860983  1.020423  1.020423   \n",
       "2    0.572300  0.147040  0.147040  0.147040  0.147040  0.147040  0.147040   \n",
       "3    1.128633  1.128633  1.128633  1.128633  1.128633  3.181596  4.012386   \n",
       "4    0.548065  0.548065  0.548065  1.441688  0.631261  0.631261  0.631261   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "113  1.346025  1.346025  1.346025  2.004300  2.004300  2.004300  4.521426   \n",
       "114  2.863282  0.035689  0.050935  0.780319  1.042465  0.838782  0.387164   \n",
       "115  2.398008  0.970365  0.906882  2.253443  0.757264  0.965530  0.677990   \n",
       "116  0.557391  0.557391  0.557391  1.452623  1.452623  1.583060  1.410292   \n",
       "117  0.821967  1.219186  1.219186  0.546986  0.546986  0.546986  0.546986   \n",
       "\n",
       "            8         9         10  ...        12        13        14  \\\n",
       "0    0.453604  0.453604   0.483920  ...  0.250571  0.250571  0.250571   \n",
       "1    1.333723  1.333723   1.333723  ...  1.582763  0.936744  0.936744   \n",
       "2    0.147040  0.147040   2.662993  ...  2.662993  2.662993  2.662993   \n",
       "3    4.012386  1.349989   1.266019  ...  1.266019  1.266019  0.492464   \n",
       "4    9.258070  1.495908   0.723835  ...  8.073005  8.073005  8.073005   \n",
       "..        ...       ...        ...  ...       ...       ...       ...   \n",
       "113  8.587040  8.587040  13.449106  ...  2.669237  2.669237  6.306398   \n",
       "114  0.397090  0.599418   0.419741  ...  0.426764  0.370313  0.279862   \n",
       "115  0.638683  0.661952   1.726219  ...  0.945944  0.611374  0.575126   \n",
       "116  1.410292  1.410292   0.270289  ...  0.270289  0.270289  0.270289   \n",
       "117  0.546986  1.347748   1.347748  ...  1.347748  1.347748  1.347748   \n",
       "\n",
       "           15        16        17        18        19        20  \\\n",
       "0    0.250571  0.250571  0.250571  0.167502  0.167502  0.167502   \n",
       "1    0.936744  0.936744  1.412754  3.283429  3.283429  3.283429   \n",
       "2    1.449779  1.449779  1.147295  0.978355  0.978355  0.978355   \n",
       "3    0.710132  0.710132  0.251398  0.251398  1.347456  1.347456   \n",
       "4    8.073005  1.124158  0.399042  0.399042  0.399042  0.561521   \n",
       "..        ...       ...       ...       ...       ...       ...   \n",
       "113  6.306398  6.306398  2.023114  2.023114  2.023114  4.570821   \n",
       "114  0.514111  0.849760  0.806333  0.423010  0.708934  0.659056   \n",
       "115  0.686191  0.793346  1.088155  0.467430  0.712183  1.889786   \n",
       "116  0.270289  0.376195  0.376195  0.337485  0.439030  0.582806   \n",
       "117  1.347748  0.168647  0.168647  0.168647  0.168647  0.168647   \n",
       "\n",
       "     target_ordinal  \n",
       "0               2.0  \n",
       "1               2.0  \n",
       "2               2.0  \n",
       "3               2.0  \n",
       "4               3.0  \n",
       "..              ...  \n",
       "113             1.0  \n",
       "114             3.0  \n",
       "115             3.0  \n",
       "116             3.0  \n",
       "117             3.0  \n",
       "\n",
       "[118 rows x 21 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the target_ordinal field\n",
    "\n",
    "y = main_dataset['target_ordinal']\n",
    "x = main_dataset.drop('target_ordinal', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target variables need to be an array with integer type\n",
    "train_y = np.array(train_y)\n",
    "test_y = np.array(test_y)\n",
    "\n",
    "train_y = train_y.astype(np.float32)\n",
    "test_y = test_y.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 4., 3., 2., 4., 3., 4., 4., 3., 1.], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the first 10 values of the train_y data set\n",
    "train_y[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 4., 3., 2., 4., 3., 4., 4., 3., 1., 4., 0., 1., 1., 1., 3., 1.,\n",
       "       1., 2., 1., 0., 0., 3., 1., 1., 3., 0., 4., 3., 2., 4., 1., 2., 4.,\n",
       "       3., 3., 1., 1., 1., 4., 1., 2., 1., 4., 0., 4., 1., 1., 1., 1., 0.,\n",
       "       4., 4., 1., 0., 3., 1., 3., 3., 2., 1., 2., 3., 0., 0., 4., 0., 1.,\n",
       "       0., 0., 3., 2., 1., 4., 1., 1., 4., 3., 2., 0., 1., 1.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keras expects a different input format:\n",
    "#Data needs to have 3 dimensions\n",
    "\n",
    "train_x = np.reshape(train_x, (train_x.shape[0], train_x.shape[1], 1))\n",
    "test_x = np.reshape(test_x, (test_x.shape[0], test_x.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((82, 20, 1), (82,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.47749913],\n",
       "        [ 4.14968236],\n",
       "        [ 4.14968236],\n",
       "        ...,\n",
       "        [ 1.84671512],\n",
       "        [ 4.90822199],\n",
       "        [ 5.59779756]],\n",
       "\n",
       "       [[ 0.13337083],\n",
       "        [ 0.13337083],\n",
       "        [ 0.13337083],\n",
       "        ...,\n",
       "        [ 0.25518546],\n",
       "        [ 0.25518546],\n",
       "        [ 0.25518546]],\n",
       "\n",
       "       [[ 0.82408761],\n",
       "        [ 0.82408761],\n",
       "        [ 0.82408761],\n",
       "        ...,\n",
       "        [ 0.5122462 ],\n",
       "        [ 0.38986542],\n",
       "        [ 1.09923091]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 1.52403174],\n",
       "        [ 1.57845135],\n",
       "        [ 1.20821972],\n",
       "        ...,\n",
       "        [ 0.01449039],\n",
       "        [ 0.01449039],\n",
       "        [ 0.05955193]],\n",
       "\n",
       "       [[ 1.76538535],\n",
       "        [ 3.16740388],\n",
       "        [ 0.32343732],\n",
       "        ...,\n",
       "        [ 0.67856092],\n",
       "        [ 9.86661401],\n",
       "        [ 7.8928672 ]],\n",
       "\n",
       "       [[ 5.09301009],\n",
       "        [12.4231635 ],\n",
       "        [ 5.97956845],\n",
       "        ...,\n",
       "        [ 4.72022147],\n",
       "        [ 7.91881218],\n",
       "        [ 7.91881218]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the baseline (0.5 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DummyClassifier(strategy=&#x27;most_frequent&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DummyClassifier</label><div class=\"sk-toggleable__content\"><pre>DummyClassifier(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DummyClassifier(strategy='most_frequent')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "\n",
    "dummy_clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Train Accuracy: 0.35365853658536583\n"
     ]
    }
   ],
   "source": [
    "#Baseline Train Accuracy\n",
    "dummy_train_pred = dummy_clf.predict(train_x)\n",
    "\n",
    "baseline_train_acc = accuracy_score(train_y, dummy_train_pred)\n",
    "\n",
    "print('Baseline Train Accuracy: {}' .format(baseline_train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Test Accuracy: 0.3888888888888889\n"
     ]
    }
   ],
   "source": [
    "#Baseline Test Accuracy\n",
    "dummy_test_pred = dummy_clf.predict(test_x)\n",
    "\n",
    "baseline_test_acc = accuracy_score(test_y, dummy_test_pred)\n",
    "\n",
    "print('Baseline Test Accuracy: {}' .format(baseline_test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a cross-sectional (i.e., a regular) Neural Network model using Keras (with only one hidden layer) (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82, 20, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\akush\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#The last layer's activation function MUST be \"softmax\" for Multiclass classification\n",
    "\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    \n",
    "    keras.layers.Flatten(input_shape=[20, 1]),\n",
    "    keras.layers.Dense(20, activation='relu'),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:From C:\\Users\\akush\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\akush\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "3/3 [==============================] - 2s 223ms/step - loss: 1.6592 - accuracy: 0.2561 - val_loss: 1.3308 - val_accuracy: 0.3611\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 1.2669 - accuracy: 0.3902 - val_loss: 1.3166 - val_accuracy: 0.4167\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.2286 - accuracy: 0.4634 - val_loss: 1.2646 - val_accuracy: 0.4167\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.1652 - accuracy: 0.5122 - val_loss: 1.2100 - val_accuracy: 0.3889\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.1184 - accuracy: 0.5366 - val_loss: 1.1836 - val_accuracy: 0.4167\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1.0764 - accuracy: 0.5366 - val_loss: 1.1619 - val_accuracy: 0.4722\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.0370 - accuracy: 0.5488 - val_loss: 1.1421 - val_accuracy: 0.4722\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.9996 - accuracy: 0.5488 - val_loss: 1.1303 - val_accuracy: 0.5000\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.9693 - accuracy: 0.5732 - val_loss: 1.1223 - val_accuracy: 0.4722\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.9359 - accuracy: 0.6098 - val_loss: 1.1147 - val_accuracy: 0.5000\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.9166 - accuracy: 0.6585 - val_loss: 1.1152 - val_accuracy: 0.5278\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.8901 - accuracy: 0.6585 - val_loss: 1.1182 - val_accuracy: 0.5278\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.8647 - accuracy: 0.6829 - val_loss: 1.1028 - val_accuracy: 0.5278\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.8401 - accuracy: 0.6829 - val_loss: 1.0861 - val_accuracy: 0.5278\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.8145 - accuracy: 0.7073 - val_loss: 1.0702 - val_accuracy: 0.5278\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.7963 - accuracy: 0.7073 - val_loss: 1.0559 - val_accuracy: 0.5833\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.7732 - accuracy: 0.7561 - val_loss: 1.0479 - val_accuracy: 0.5833\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7536 - accuracy: 0.7683 - val_loss: 1.0461 - val_accuracy: 0.5833\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.7307 - accuracy: 0.7683 - val_loss: 1.0458 - val_accuracy: 0.5556\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.7108 - accuracy: 0.7683 - val_loss: 1.0494 - val_accuracy: 0.5556\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6939 - accuracy: 0.7927 - val_loss: 1.0478 - val_accuracy: 0.5556\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6732 - accuracy: 0.8049 - val_loss: 1.0392 - val_accuracy: 0.5556\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6556 - accuracy: 0.7927 - val_loss: 1.0354 - val_accuracy: 0.5833\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.6399 - accuracy: 0.7805 - val_loss: 1.0396 - val_accuracy: 0.6111\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6222 - accuracy: 0.8049 - val_loss: 1.0422 - val_accuracy: 0.6111\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6070 - accuracy: 0.7805 - val_loss: 1.0441 - val_accuracy: 0.6111\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5911 - accuracy: 0.7927 - val_loss: 1.0613 - val_accuracy: 0.6111\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.5765 - accuracy: 0.7927 - val_loss: 1.0736 - val_accuracy: 0.5556\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5596 - accuracy: 0.8049 - val_loss: 1.0607 - val_accuracy: 0.6111\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5470 - accuracy: 0.7927 - val_loss: 1.0454 - val_accuracy: 0.6111\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5345 - accuracy: 0.8171 - val_loss: 1.0492 - val_accuracy: 0.6111\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5188 - accuracy: 0.8293 - val_loss: 1.0707 - val_accuracy: 0.6111\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5074 - accuracy: 0.8293 - val_loss: 1.1087 - val_accuracy: 0.5278\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4982 - accuracy: 0.8415 - val_loss: 1.0940 - val_accuracy: 0.6111\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4842 - accuracy: 0.8415 - val_loss: 1.0885 - val_accuracy: 0.5833\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4739 - accuracy: 0.8415 - val_loss: 1.0925 - val_accuracy: 0.5833\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4632 - accuracy: 0.8415 - val_loss: 1.0986 - val_accuracy: 0.5833\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4492 - accuracy: 0.8537 - val_loss: 1.1084 - val_accuracy: 0.5278\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4377 - accuracy: 0.8659 - val_loss: 1.1028 - val_accuracy: 0.5833\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4323 - accuracy: 0.8659 - val_loss: 1.1065 - val_accuracy: 0.5833\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4208 - accuracy: 0.8659 - val_loss: 1.1174 - val_accuracy: 0.5833\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4112 - accuracy: 0.8659 - val_loss: 1.1295 - val_accuracy: 0.5833\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4034 - accuracy: 0.8659 - val_loss: 1.1344 - val_accuracy: 0.5833\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3964 - accuracy: 0.8537 - val_loss: 1.1564 - val_accuracy: 0.5556\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3907 - accuracy: 0.8780 - val_loss: 1.1843 - val_accuracy: 0.5556\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.3814 - accuracy: 0.8780 - val_loss: 1.1877 - val_accuracy: 0.5833\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3710 - accuracy: 0.8902 - val_loss: 1.2124 - val_accuracy: 0.5833\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3697 - accuracy: 0.8780 - val_loss: 1.2400 - val_accuracy: 0.5556\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3600 - accuracy: 0.8902 - val_loss: 1.2320 - val_accuracy: 0.5833\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.3534 - accuracy: 0.8902 - val_loss: 1.2475 - val_accuracy: 0.5833\n"
     ]
    }
   ],
   "source": [
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# If multiclass, use \"sparse_categorical_crossentropy\" as the loss function\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=50,\n",
    "                    validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.2474710941314697, 0.5833333134651184]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.25\n",
      "accuracy: 58.33%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RNN with one layer and Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 20\n",
    "n_inputs = 1\n",
    "\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    \n",
    "    keras.layers.SimpleRNN(20, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
    "\n",
    "callback = [earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 2s 267ms/step - loss: 1.5642 - accuracy: 0.1463 - val_loss: 1.2910 - val_accuracy: 0.5278\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 1.2502 - accuracy: 0.5122 - val_loss: 1.1691 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 1.0998 - accuracy: 0.5976 - val_loss: 1.0851 - val_accuracy: 0.5278\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1.0040 - accuracy: 0.6707 - val_loss: 1.0536 - val_accuracy: 0.5556\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.9426 - accuracy: 0.7073 - val_loss: 1.0374 - val_accuracy: 0.6111\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.8926 - accuracy: 0.6707 - val_loss: 0.9854 - val_accuracy: 0.5556\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.8745 - accuracy: 0.6707 - val_loss: 0.9553 - val_accuracy: 0.5833\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.8222 - accuracy: 0.6585 - val_loss: 0.9235 - val_accuracy: 0.5833\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.7908 - accuracy: 0.6463 - val_loss: 0.9320 - val_accuracy: 0.5833\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.7637 - accuracy: 0.6341 - val_loss: 0.8937 - val_accuracy: 0.5556\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.7743 - accuracy: 0.6463 - val_loss: 0.8700 - val_accuracy: 0.7222\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.7217 - accuracy: 0.7195 - val_loss: 0.8612 - val_accuracy: 0.6944\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.7090 - accuracy: 0.6829 - val_loss: 0.8601 - val_accuracy: 0.6944\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7314 - accuracy: 0.6707 - val_loss: 0.8461 - val_accuracy: 0.5833\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7040 - accuracy: 0.6829 - val_loss: 0.8316 - val_accuracy: 0.6111\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6466 - accuracy: 0.7073 - val_loss: 0.8176 - val_accuracy: 0.6389\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6723 - accuracy: 0.7805 - val_loss: 0.8128 - val_accuracy: 0.6111\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7387 - accuracy: 0.7073 - val_loss: 0.9565 - val_accuracy: 0.5833\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7264 - accuracy: 0.7195 - val_loss: 0.7752 - val_accuracy: 0.7222\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.7067 - accuracy: 0.7195 - val_loss: 0.8392 - val_accuracy: 0.7500\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.7392 - accuracy: 0.7195 - val_loss: 0.9392 - val_accuracy: 0.6111\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6527 - accuracy: 0.7073 - val_loss: 0.9415 - val_accuracy: 0.6111\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6207 - accuracy: 0.7073 - val_loss: 0.9061 - val_accuracy: 0.5556\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.5991 - accuracy: 0.7439 - val_loss: 0.8286 - val_accuracy: 0.7222\n",
      "Epoch 24: early stopping\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# If multiclass, use \"sparse_categorical_crossentropy\" as the loss function\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=50,\n",
    "                    validation_data=(test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8286284804344177, 0.7222222089767456]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.83\n",
      "accuracy: 72.22%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a deep cross-sectional (i.e., regular) Neural Network model using Keras (with two or more hidden layers) (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 20\n",
    "n_inputs = 1\n",
    "\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(16, return_sequences=True, input_shape=[n_steps, n_inputs] ),  # Input layer\n",
    "    keras.layers.SimpleRNN(16, return_sequences=True),  # Hidden layer (first hidden layer)\n",
    "    keras.layers.SimpleRNN(16),     # Hidden layer (second hidden layer)\n",
    "    keras.layers.Dense(5, activation='softmax')   # Output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3/3 [==============================] - 6s 466ms/step - loss: 1.6816 - accuracy: 0.2439 - val_loss: 1.3495 - val_accuracy: 0.3889\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 1.1348 - accuracy: 0.6098 - val_loss: 1.1037 - val_accuracy: 0.6111\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.9977 - accuracy: 0.6098 - val_loss: 1.0318 - val_accuracy: 0.4722\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.8781 - accuracy: 0.6707 - val_loss: 1.0198 - val_accuracy: 0.4722\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.8329 - accuracy: 0.6707 - val_loss: 0.9422 - val_accuracy: 0.5556\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.7429 - accuracy: 0.6829 - val_loss: 0.9273 - val_accuracy: 0.5833\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.7181 - accuracy: 0.7317 - val_loss: 0.8909 - val_accuracy: 0.5278\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6617 - accuracy: 0.7683 - val_loss: 0.8564 - val_accuracy: 0.5833\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5916 - accuracy: 0.7683 - val_loss: 0.8022 - val_accuracy: 0.6389\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.6059 - accuracy: 0.7561 - val_loss: 0.7948 - val_accuracy: 0.6389\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.5197 - accuracy: 0.8049 - val_loss: 0.8397 - val_accuracy: 0.6667\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4914 - accuracy: 0.8049 - val_loss: 0.8507 - val_accuracy: 0.7222\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4654 - accuracy: 0.8415 - val_loss: 0.9044 - val_accuracy: 0.6389\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4318 - accuracy: 0.8780 - val_loss: 0.7919 - val_accuracy: 0.6944\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3963 - accuracy: 0.8780 - val_loss: 0.8793 - val_accuracy: 0.6667\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.3561 - accuracy: 0.8659 - val_loss: 0.8579 - val_accuracy: 0.6667\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.3438 - accuracy: 0.8902 - val_loss: 0.7943 - val_accuracy: 0.6944\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.2828 - accuracy: 0.9390 - val_loss: 0.8943 - val_accuracy: 0.6944\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.2739 - accuracy: 0.9512 - val_loss: 0.7826 - val_accuracy: 0.7222\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.2470 - accuracy: 0.9146 - val_loss: 0.8169 - val_accuracy: 0.6389\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=20,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8169397115707397, 0.6388888955116272]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.82\n",
      "accuracy: 63.89%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a LSTM Model (with only one layer) (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 20\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    \n",
    "    keras.layers.LSTM(20, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3/3 [==============================] - 5s 549ms/step - loss: 1.7017 - accuracy: 0.1951 - val_loss: 1.5334 - val_accuracy: 0.2222\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 1.4547 - accuracy: 0.3659 - val_loss: 1.3662 - val_accuracy: 0.5278\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 1.3273 - accuracy: 0.5000 - val_loss: 1.2366 - val_accuracy: 0.5833\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 1.2097 - accuracy: 0.5366 - val_loss: 1.1123 - val_accuracy: 0.6111\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 1.1038 - accuracy: 0.5610 - val_loss: 0.9906 - val_accuracy: 0.6111\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 1.0056 - accuracy: 0.6220 - val_loss: 0.8674 - val_accuracy: 0.5556\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.9405 - accuracy: 0.5610 - val_loss: 0.7808 - val_accuracy: 0.6111\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.8789 - accuracy: 0.6220 - val_loss: 0.7458 - val_accuracy: 0.6111\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.8367 - accuracy: 0.6341 - val_loss: 0.7312 - val_accuracy: 0.6111\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.8080 - accuracy: 0.5854 - val_loss: 0.7231 - val_accuracy: 0.6111\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.7735 - accuracy: 0.6463 - val_loss: 0.7128 - val_accuracy: 0.6667\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.7721 - accuracy: 0.6707 - val_loss: 0.7180 - val_accuracy: 0.6944\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7552 - accuracy: 0.6829 - val_loss: 0.7327 - val_accuracy: 0.5833\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7305 - accuracy: 0.6707 - val_loss: 0.7248 - val_accuracy: 0.5833\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.7131 - accuracy: 0.7073 - val_loss: 0.7278 - val_accuracy: 0.5833\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.7079 - accuracy: 0.7073 - val_loss: 0.7166 - val_accuracy: 0.6111\n",
      "Epoch 16: early stopping\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=20,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7165691256523132, 0.6111111044883728]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.72\n",
      "accuracy: 61.11%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a deep LSTM Model (with only two layers) (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 20\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.LSTM(16, return_sequences=True, input_shape=[n_steps, n_inputs]),  # First LSTM layer\n",
    "    keras.layers.LSTM(16),  # Second LSTM layer\n",
    "    keras.layers.Dense(5, activation='softmax')  # Output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3/3 [==============================] - 9s 887ms/step - loss: 1.6222 - accuracy: 0.2317 - val_loss: 1.3978 - val_accuracy: 0.3889\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 1.3543 - accuracy: 0.3659 - val_loss: 1.2451 - val_accuracy: 0.4444\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 1.2265 - accuracy: 0.4634 - val_loss: 1.0751 - val_accuracy: 0.5278\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 1.0826 - accuracy: 0.6098 - val_loss: 0.9809 - val_accuracy: 0.6389\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 1.0298 - accuracy: 0.5732 - val_loss: 0.9353 - val_accuracy: 0.6111\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.9580 - accuracy: 0.6220 - val_loss: 0.8688 - val_accuracy: 0.5556\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.9251 - accuracy: 0.5854 - val_loss: 0.8122 - val_accuracy: 0.5833\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.8608 - accuracy: 0.5732 - val_loss: 0.7997 - val_accuracy: 0.5833\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.8438 - accuracy: 0.6341 - val_loss: 0.7649 - val_accuracy: 0.5278\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.7920 - accuracy: 0.5854 - val_loss: 0.7615 - val_accuracy: 0.5556\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.7768 - accuracy: 0.5976 - val_loss: 0.7503 - val_accuracy: 0.6389\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.7660 - accuracy: 0.6220 - val_loss: 0.7221 - val_accuracy: 0.6944\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.7649 - accuracy: 0.6341 - val_loss: 0.7264 - val_accuracy: 0.6944\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.7523 - accuracy: 0.6585 - val_loss: 0.6921 - val_accuracy: 0.7222\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.7170 - accuracy: 0.6585 - val_loss: 0.7389 - val_accuracy: 0.6111\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.7497 - accuracy: 0.6341 - val_loss: 0.7464 - val_accuracy: 0.5556\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7378 - accuracy: 0.6707 - val_loss: 0.6933 - val_accuracy: 0.5556\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.7544 - accuracy: 0.6585 - val_loss: 0.7146 - val_accuracy: 0.5833\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7360 - accuracy: 0.6585 - val_loss: 0.7105 - val_accuracy: 0.7222\n",
      "Epoch 19: early stopping\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=20,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7105157375335693, 0.7222222089767456]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.71\n",
      "accuracy: 72.22%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a GRU Model (with only one layer) (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 20\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(20, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3/3 [==============================] - 5s 629ms/step - loss: 1.2127 - accuracy: 0.4146 - val_loss: 1.2341 - val_accuracy: 0.3889\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 1.1292 - accuracy: 0.5366 - val_loss: 1.1800 - val_accuracy: 0.4444\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 1.0700 - accuracy: 0.5488 - val_loss: 1.1019 - val_accuracy: 0.4167\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1.0013 - accuracy: 0.5732 - val_loss: 1.0483 - val_accuracy: 0.5278\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.9472 - accuracy: 0.5610 - val_loss: 1.0201 - val_accuracy: 0.5556\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.8960 - accuracy: 0.5976 - val_loss: 0.9180 - val_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.8374 - accuracy: 0.5610 - val_loss: 0.8235 - val_accuracy: 0.5556\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.8384 - accuracy: 0.5732 - val_loss: 0.7640 - val_accuracy: 0.6111\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.8050 - accuracy: 0.6098 - val_loss: 0.7763 - val_accuracy: 0.5556\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.8044 - accuracy: 0.6220 - val_loss: 0.7962 - val_accuracy: 0.6944\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.7697 - accuracy: 0.5976 - val_loss: 0.7646 - val_accuracy: 0.6111\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.7738 - accuracy: 0.6220 - val_loss: 0.7630 - val_accuracy: 0.6111\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.7527 - accuracy: 0.6341 - val_loss: 0.7586 - val_accuracy: 0.5556\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.7429 - accuracy: 0.6707 - val_loss: 0.7825 - val_accuracy: 0.5833\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7391 - accuracy: 0.6707 - val_loss: 0.7212 - val_accuracy: 0.6111\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.7270 - accuracy: 0.6463 - val_loss: 0.7030 - val_accuracy: 0.6111\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.7132 - accuracy: 0.6463 - val_loss: 0.7314 - val_accuracy: 0.6944\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.7246 - accuracy: 0.6585 - val_loss: 0.8114 - val_accuracy: 0.6667\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.7089 - accuracy: 0.6829 - val_loss: 0.7345 - val_accuracy: 0.5278\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.6879 - accuracy: 0.6341 - val_loss: 0.7106 - val_accuracy: 0.5833\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=20,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7105714082717896, 0.5833333134651184]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.71\n",
      "accuracy: 58.33%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a deep GRU Model (with only two layers) (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 20\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(16, return_sequences=True, input_shape=[n_steps, n_inputs]),  # First GRU layer\n",
    "    keras.layers.GRU(16),  # Second GRU layer\n",
    "    keras.layers.Dense(5, activation='softmax')  # Output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3/3 [==============================] - 9s 837ms/step - loss: 1.5562 - accuracy: 0.2195 - val_loss: 1.2803 - val_accuracy: 0.3889\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.2469 - accuracy: 0.3415 - val_loss: 1.1778 - val_accuracy: 0.3611\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 1.1475 - accuracy: 0.4268 - val_loss: 1.0578 - val_accuracy: 0.6667\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 1.0418 - accuracy: 0.5610 - val_loss: 0.9865 - val_accuracy: 0.6944\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.9717 - accuracy: 0.6220 - val_loss: 0.9667 - val_accuracy: 0.5833\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.9332 - accuracy: 0.5854 - val_loss: 0.9568 - val_accuracy: 0.5278\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.8768 - accuracy: 0.6220 - val_loss: 0.8652 - val_accuracy: 0.5278\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.8100 - accuracy: 0.6341 - val_loss: 0.8463 - val_accuracy: 0.6111\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.8218 - accuracy: 0.6707 - val_loss: 0.7988 - val_accuracy: 0.5833\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.7767 - accuracy: 0.6463 - val_loss: 0.7708 - val_accuracy: 0.5278\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.7551 - accuracy: 0.6585 - val_loss: 0.7152 - val_accuracy: 0.5556\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.7285 - accuracy: 0.6951 - val_loss: 0.7057 - val_accuracy: 0.6944\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.7297 - accuracy: 0.6951 - val_loss: 0.7152 - val_accuracy: 0.6944\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.7241 - accuracy: 0.6951 - val_loss: 0.7175 - val_accuracy: 0.6389\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.6892 - accuracy: 0.6951 - val_loss: 0.7385 - val_accuracy: 0.5833\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.7052 - accuracy: 0.6707 - val_loss: 0.7484 - val_accuracy: 0.6111\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.7200 - accuracy: 0.6951 - val_loss: 0.7195 - val_accuracy: 0.6667\n",
      "Epoch 17: early stopping\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=20,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7194885611534119, 0.6666666865348816]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.72\n",
      "accuracy: 66.67%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List the test values of each model you built (0.5 points)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Baseline Train Accuracy: 0.35\n",
    "Baseline Test Accuracy: 0.39\n",
    "------------------------------------------\n",
    "Neural Network model (1 hidden layer)\n",
    "\n",
    "loss: 1.25\n",
    "accuracy: 58.33%\n",
    "------------------------------------------\n",
    "Neural Network model (2 or more hidden layer)\n",
    "\n",
    "loss: 0.82\n",
    "accuracy: 63.89%\n",
    "------------------------------------------\n",
    "LSTM Model  (1 layer)\n",
    "\n",
    "loss: 0.72\n",
    "accuracy: 61.11%\n",
    "------------------------------------------\n",
    "LSTM Model (2  layer)\n",
    "\n",
    "loss: 0.71\n",
    "accuracy: 72.22%\n",
    "------------------------------------------\n",
    "GRU Model (1 layer)\n",
    "\n",
    "loss: 0.71\n",
    "accuracy: 58.33%\n",
    "------------------------------------------\n",
    "GRU Model (2 layer)\n",
    "\n",
    "loss: 0.72\n",
    "accuracy: 66.67%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which model performs the best and why? (0.5 points) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "LSTM Model (2  layer)\n",
    "\n",
    "loss: 0.71\n",
    "accuracy: 72.22%\n",
    "\n",
    "I believe that the 2-layer LSTM model works best among all the options, with the highest score of 72.22% and a low mistake rate of 0.71. It's better because it has two layers that are really good at understanding patterns in data that changes over time, like a series of events. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does it compare to baseline? (0.5 points)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Baseline Train Accuracy: 0.35\n",
    "Baseline Test Accuracy: 0.39\n",
    "\n",
    "LSTM Model (2  layer)\n",
    "\n",
    "loss: 0.71\n",
    "accuracy: 72.22%\n",
    "\n",
    "The 2-layer LSTM model is much better than the baseline model we started with. The baseline model could only get 35% to 39% of the answers right, which means it was often wrong. But the LSTM model with two layers got 72.22% right, which is way better. This big jump in performance shows that the LSTM model is really good at understanding the information provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra credit: 2 points\n",
    "\n",
    "The dataset is very small. This means your test values are likely unreliable. Use your best model and run a 10-fold cross validation on it. Then, find and report the mean accuracy score.\n",
    "\n",
    "Note: to be eligible for this extra credit, you should run your 10-fold cross validation on the unsplit data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>target_ordinal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.179784</td>\n",
       "      <td>1.179784</td>\n",
       "      <td>0.810629</td>\n",
       "      <td>0.810629</td>\n",
       "      <td>1.041816</td>\n",
       "      <td>1.041816</td>\n",
       "      <td>1.041816</td>\n",
       "      <td>0.453604</td>\n",
       "      <td>0.453604</td>\n",
       "      <td>0.483920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250571</td>\n",
       "      <td>0.250571</td>\n",
       "      <td>0.250571</td>\n",
       "      <td>0.250571</td>\n",
       "      <td>0.250571</td>\n",
       "      <td>0.250571</td>\n",
       "      <td>0.167502</td>\n",
       "      <td>0.167502</td>\n",
       "      <td>0.167502</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.115912</td>\n",
       "      <td>0.860983</td>\n",
       "      <td>0.860983</td>\n",
       "      <td>0.860983</td>\n",
       "      <td>0.860983</td>\n",
       "      <td>1.020423</td>\n",
       "      <td>1.020423</td>\n",
       "      <td>1.333723</td>\n",
       "      <td>1.333723</td>\n",
       "      <td>1.333723</td>\n",
       "      <td>...</td>\n",
       "      <td>1.582763</td>\n",
       "      <td>0.936744</td>\n",
       "      <td>0.936744</td>\n",
       "      <td>0.936744</td>\n",
       "      <td>0.936744</td>\n",
       "      <td>1.412754</td>\n",
       "      <td>3.283429</td>\n",
       "      <td>3.283429</td>\n",
       "      <td>3.283429</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.572300</td>\n",
       "      <td>0.147040</td>\n",
       "      <td>0.147040</td>\n",
       "      <td>0.147040</td>\n",
       "      <td>0.147040</td>\n",
       "      <td>0.147040</td>\n",
       "      <td>0.147040</td>\n",
       "      <td>0.147040</td>\n",
       "      <td>0.147040</td>\n",
       "      <td>2.662993</td>\n",
       "      <td>...</td>\n",
       "      <td>2.662993</td>\n",
       "      <td>2.662993</td>\n",
       "      <td>2.662993</td>\n",
       "      <td>1.449779</td>\n",
       "      <td>1.449779</td>\n",
       "      <td>1.147295</td>\n",
       "      <td>0.978355</td>\n",
       "      <td>0.978355</td>\n",
       "      <td>0.978355</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.128633</td>\n",
       "      <td>1.128633</td>\n",
       "      <td>1.128633</td>\n",
       "      <td>1.128633</td>\n",
       "      <td>1.128633</td>\n",
       "      <td>3.181596</td>\n",
       "      <td>4.012386</td>\n",
       "      <td>4.012386</td>\n",
       "      <td>1.349989</td>\n",
       "      <td>1.266019</td>\n",
       "      <td>...</td>\n",
       "      <td>1.266019</td>\n",
       "      <td>1.266019</td>\n",
       "      <td>0.492464</td>\n",
       "      <td>0.710132</td>\n",
       "      <td>0.710132</td>\n",
       "      <td>0.251398</td>\n",
       "      <td>0.251398</td>\n",
       "      <td>1.347456</td>\n",
       "      <td>1.347456</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.548065</td>\n",
       "      <td>0.548065</td>\n",
       "      <td>0.548065</td>\n",
       "      <td>1.441688</td>\n",
       "      <td>0.631261</td>\n",
       "      <td>0.631261</td>\n",
       "      <td>0.631261</td>\n",
       "      <td>9.258070</td>\n",
       "      <td>1.495908</td>\n",
       "      <td>0.723835</td>\n",
       "      <td>...</td>\n",
       "      <td>8.073005</td>\n",
       "      <td>8.073005</td>\n",
       "      <td>8.073005</td>\n",
       "      <td>8.073005</td>\n",
       "      <td>1.124158</td>\n",
       "      <td>0.399042</td>\n",
       "      <td>0.399042</td>\n",
       "      <td>0.399042</td>\n",
       "      <td>0.561521</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>1.346025</td>\n",
       "      <td>1.346025</td>\n",
       "      <td>1.346025</td>\n",
       "      <td>2.004300</td>\n",
       "      <td>2.004300</td>\n",
       "      <td>2.004300</td>\n",
       "      <td>4.521426</td>\n",
       "      <td>8.587040</td>\n",
       "      <td>8.587040</td>\n",
       "      <td>13.449106</td>\n",
       "      <td>...</td>\n",
       "      <td>2.669237</td>\n",
       "      <td>2.669237</td>\n",
       "      <td>6.306398</td>\n",
       "      <td>6.306398</td>\n",
       "      <td>6.306398</td>\n",
       "      <td>2.023114</td>\n",
       "      <td>2.023114</td>\n",
       "      <td>2.023114</td>\n",
       "      <td>4.570821</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2.863282</td>\n",
       "      <td>0.035689</td>\n",
       "      <td>0.050935</td>\n",
       "      <td>0.780319</td>\n",
       "      <td>1.042465</td>\n",
       "      <td>0.838782</td>\n",
       "      <td>0.387164</td>\n",
       "      <td>0.397090</td>\n",
       "      <td>0.599418</td>\n",
       "      <td>0.419741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.426764</td>\n",
       "      <td>0.370313</td>\n",
       "      <td>0.279862</td>\n",
       "      <td>0.514111</td>\n",
       "      <td>0.849760</td>\n",
       "      <td>0.806333</td>\n",
       "      <td>0.423010</td>\n",
       "      <td>0.708934</td>\n",
       "      <td>0.659056</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2.398008</td>\n",
       "      <td>0.970365</td>\n",
       "      <td>0.906882</td>\n",
       "      <td>2.253443</td>\n",
       "      <td>0.757264</td>\n",
       "      <td>0.965530</td>\n",
       "      <td>0.677990</td>\n",
       "      <td>0.638683</td>\n",
       "      <td>0.661952</td>\n",
       "      <td>1.726219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.945944</td>\n",
       "      <td>0.611374</td>\n",
       "      <td>0.575126</td>\n",
       "      <td>0.686191</td>\n",
       "      <td>0.793346</td>\n",
       "      <td>1.088155</td>\n",
       "      <td>0.467430</td>\n",
       "      <td>0.712183</td>\n",
       "      <td>1.889786</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.557391</td>\n",
       "      <td>0.557391</td>\n",
       "      <td>0.557391</td>\n",
       "      <td>1.452623</td>\n",
       "      <td>1.452623</td>\n",
       "      <td>1.583060</td>\n",
       "      <td>1.410292</td>\n",
       "      <td>1.410292</td>\n",
       "      <td>1.410292</td>\n",
       "      <td>0.270289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270289</td>\n",
       "      <td>0.270289</td>\n",
       "      <td>0.270289</td>\n",
       "      <td>0.270289</td>\n",
       "      <td>0.376195</td>\n",
       "      <td>0.376195</td>\n",
       "      <td>0.337485</td>\n",
       "      <td>0.439030</td>\n",
       "      <td>0.582806</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.821967</td>\n",
       "      <td>1.219186</td>\n",
       "      <td>1.219186</td>\n",
       "      <td>0.546986</td>\n",
       "      <td>0.546986</td>\n",
       "      <td>0.546986</td>\n",
       "      <td>0.546986</td>\n",
       "      <td>0.546986</td>\n",
       "      <td>1.347748</td>\n",
       "      <td>1.347748</td>\n",
       "      <td>...</td>\n",
       "      <td>1.347748</td>\n",
       "      <td>1.347748</td>\n",
       "      <td>1.347748</td>\n",
       "      <td>1.347748</td>\n",
       "      <td>0.168647</td>\n",
       "      <td>0.168647</td>\n",
       "      <td>0.168647</td>\n",
       "      <td>0.168647</td>\n",
       "      <td>0.168647</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            1         2         3         4         5         6         7  \\\n",
       "0    1.179784  1.179784  0.810629  0.810629  1.041816  1.041816  1.041816   \n",
       "1    1.115912  0.860983  0.860983  0.860983  0.860983  1.020423  1.020423   \n",
       "2    0.572300  0.147040  0.147040  0.147040  0.147040  0.147040  0.147040   \n",
       "3    1.128633  1.128633  1.128633  1.128633  1.128633  3.181596  4.012386   \n",
       "4    0.548065  0.548065  0.548065  1.441688  0.631261  0.631261  0.631261   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "113  1.346025  1.346025  1.346025  2.004300  2.004300  2.004300  4.521426   \n",
       "114  2.863282  0.035689  0.050935  0.780319  1.042465  0.838782  0.387164   \n",
       "115  2.398008  0.970365  0.906882  2.253443  0.757264  0.965530  0.677990   \n",
       "116  0.557391  0.557391  0.557391  1.452623  1.452623  1.583060  1.410292   \n",
       "117  0.821967  1.219186  1.219186  0.546986  0.546986  0.546986  0.546986   \n",
       "\n",
       "            8         9         10  ...        12        13        14  \\\n",
       "0    0.453604  0.453604   0.483920  ...  0.250571  0.250571  0.250571   \n",
       "1    1.333723  1.333723   1.333723  ...  1.582763  0.936744  0.936744   \n",
       "2    0.147040  0.147040   2.662993  ...  2.662993  2.662993  2.662993   \n",
       "3    4.012386  1.349989   1.266019  ...  1.266019  1.266019  0.492464   \n",
       "4    9.258070  1.495908   0.723835  ...  8.073005  8.073005  8.073005   \n",
       "..        ...       ...        ...  ...       ...       ...       ...   \n",
       "113  8.587040  8.587040  13.449106  ...  2.669237  2.669237  6.306398   \n",
       "114  0.397090  0.599418   0.419741  ...  0.426764  0.370313  0.279862   \n",
       "115  0.638683  0.661952   1.726219  ...  0.945944  0.611374  0.575126   \n",
       "116  1.410292  1.410292   0.270289  ...  0.270289  0.270289  0.270289   \n",
       "117  0.546986  1.347748   1.347748  ...  1.347748  1.347748  1.347748   \n",
       "\n",
       "           15        16        17        18        19        20  \\\n",
       "0    0.250571  0.250571  0.250571  0.167502  0.167502  0.167502   \n",
       "1    0.936744  0.936744  1.412754  3.283429  3.283429  3.283429   \n",
       "2    1.449779  1.449779  1.147295  0.978355  0.978355  0.978355   \n",
       "3    0.710132  0.710132  0.251398  0.251398  1.347456  1.347456   \n",
       "4    8.073005  1.124158  0.399042  0.399042  0.399042  0.561521   \n",
       "..        ...       ...       ...       ...       ...       ...   \n",
       "113  6.306398  6.306398  2.023114  2.023114  2.023114  4.570821   \n",
       "114  0.514111  0.849760  0.806333  0.423010  0.708934  0.659056   \n",
       "115  0.686191  0.793346  1.088155  0.467430  0.712183  1.889786   \n",
       "116  0.270289  0.376195  0.376195  0.337485  0.439030  0.582806   \n",
       "117  1.347748  0.168647  0.168647  0.168647  0.168647  0.168647   \n",
       "\n",
       "     target_ordinal  \n",
       "0               2.0  \n",
       "1               2.0  \n",
       "2               2.0  \n",
       "3               2.0  \n",
       "4               3.0  \n",
       "..              ...  \n",
       "113             1.0  \n",
       "114             3.0  \n",
       "115             3.0  \n",
       "116             3.0  \n",
       "117             3.0  \n",
       "\n",
       "[118 rows x 21 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getthing the main dataset here which has target_ordinal field but no target field \n",
    "# as we need to perform operations on Ordinal field.\n",
    "\n",
    "main_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separating the target ordinal\n",
    "\n",
    "y = main_dataset['target_ordinal']\n",
    "x = main_dataset.drop('target_ordinal', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target variables need to be an array with integer type\n",
    "\n",
    "y = np.array(y)\n",
    "y = y.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 3, 3, 3, 3, 3, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the first 10 values of the train_y data set\n",
    "\n",
    "y[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert input variables to a 2-D array with float data type\n",
    "\n",
    "x= np.array(x)\n",
    "x = x.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.1797843 , 1.1797843 , 0.81062883, ..., 0.16750231, 0.16750231,\n",
       "        0.16750231],\n",
       "       [1.1159117 , 0.86098343, 0.86098343, ..., 3.283429  , 3.283429  ,\n",
       "        3.283429  ],\n",
       "       [0.5722996 , 0.14704004, 0.14704004, ..., 0.97835505, 0.97835505,\n",
       "        0.97835505],\n",
       "       ...,\n",
       "       [2.3980083 , 0.97036546, 0.90688217, ..., 0.46742973, 0.7121831 ,\n",
       "        1.8897858 ],\n",
       "       [0.5573906 , 0.5573906 , 0.5573906 , ..., 0.3374849 , 0.43902954,\n",
       "        0.5828057 ],\n",
       "       [0.8219675 , 1.2191864 , 1.2191864 , ..., 0.16864732, 0.16864732,\n",
       "        0.16864732]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape X to be 3D [samples, time steps, features per step]\n",
    "\n",
    "x_reshaped = np.reshape(x, (x.shape[0], x.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.1797843 ],\n",
       "        [1.1797843 ],\n",
       "        [0.81062883],\n",
       "        ...,\n",
       "        [0.16750231],\n",
       "        [0.16750231],\n",
       "        [0.16750231]],\n",
       "\n",
       "       [[1.1159117 ],\n",
       "        [0.86098343],\n",
       "        [0.86098343],\n",
       "        ...,\n",
       "        [3.283429  ],\n",
       "        [3.283429  ],\n",
       "        [3.283429  ]],\n",
       "\n",
       "       [[0.5722996 ],\n",
       "        [0.14704004],\n",
       "        [0.14704004],\n",
       "        ...,\n",
       "        [0.97835505],\n",
       "        [0.97835505],\n",
       "        [0.97835505]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[2.3980083 ],\n",
       "        [0.97036546],\n",
       "        [0.90688217],\n",
       "        ...,\n",
       "        [0.46742973],\n",
       "        [0.7121831 ],\n",
       "        [1.8897858 ]],\n",
       "\n",
       "       [[0.5573906 ],\n",
       "        [0.5573906 ],\n",
       "        [0.5573906 ],\n",
       "        ...,\n",
       "        [0.3374849 ],\n",
       "        [0.43902954],\n",
       "        [0.5828057 ]],\n",
       "\n",
       "       [[0.8219675 ],\n",
       "        [1.2191864 ],\n",
       "        [1.2191864 ],\n",
       "        ...,\n",
       "        [0.16864732],\n",
       "        [0.16864732],\n",
       "        [0.16864732]]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((118, 20, 1), (118,))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Keras expects a different input format:\n",
    "#Data needs to have 3 dimensions\n",
    "\n",
    "x_reshaped.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing K folds to perform cross validation\n",
    "\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#question asked to Use best model and run a 10-fold cross validation on it\n",
    "# my best model was LSTM model \n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my best model was LSTM model  \n",
    "\n",
    "def create_model(n_steps=20, n_inputs=1):\n",
    "    \n",
    "    model = keras.models.Sequential([\n",
    "        \n",
    "            keras.layers.LSTM(16, return_sequences=True, input_shape=[n_steps, n_inputs]),\n",
    "            keras.layers.LSTM(16, return_sequences=True),\n",
    "            keras.layers.LSTM(16),\n",
    "            keras.layers.Dense(5, activation='softmax')\n",
    "        \n",
    "        ])\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "    \n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Loss = 0.5751311182975769, Accuracy = 75.0%\n",
      "Epoch 16: early stopping\n",
      "Fold 2: Loss = 0.9005749225616455, Accuracy = 75.0%\n",
      "Epoch 10: early stopping\n",
      "Fold 3: Loss = 0.6350502371788025, Accuracy = 75.0%\n",
      "Epoch 12: early stopping\n",
      "Fold 4: Loss = 0.7705190181732178, Accuracy = 75.0%\n",
      "Epoch 15: early stopping\n",
      "Fold 5: Loss = 1.0237871408462524, Accuracy = 66.66666865348816%\n",
      "Epoch 15: early stopping\n",
      "Fold 6: Loss = 0.6153814196586609, Accuracy = 66.66666865348816%\n",
      "Epoch 17: early stopping\n",
      "Fold 7: Loss = 1.181280493736267, Accuracy = 58.33333134651184%\n",
      "Epoch 10: early stopping\n",
      "Fold 8: Loss = 0.7284666895866394, Accuracy = 66.66666865348816%\n",
      "Epoch 9: early stopping\n",
      "Fold 9: Loss = 1.5268641710281372, Accuracy = 36.36363744735718%\n",
      "Epoch 12: early stopping\n",
      "Fold 10: Loss = 0.8288101553916931, Accuracy = 63.63636255264282%\n"
     ]
    }
   ],
   "source": [
    "fold_no = 1\n",
    "scores = []  # This will collect the 'loss' and 'accuracy' for each fold\n",
    "\n",
    "for train, test in kfold.split(x_reshaped, y):\n",
    "    \n",
    "    model = create_model(n_steps=20, n_inputs=1)\n",
    "    earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(x_reshaped[train], y[train], epochs=20, validation_split=0.1, callbacks=[earlystop], verbose=0)\n",
    "    \n",
    "    # Evaluate the model on the test set\n",
    "    score = model.evaluate(x_reshaped[test], y[test], verbose=0)\n",
    "    scores.append(score)\n",
    "    \n",
    "    print(f\"Fold {fold_no}: Loss = {score[0]}, Accuracy = {score[1]*100}%\")\n",
    "    \n",
    "    fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Loss: 0.88\n",
      "Mean Accuracy: 65.83%\n"
     ]
    }
   ],
   "source": [
    "mean_loss = np.mean([s[0] for s in scores])  # Calculating mean loss\n",
    "mean_accuracy = np.mean([s[1] for s in scores])  # Calculating mean accuracy\n",
    "\n",
    "print(f\"Mean Loss: {mean_loss:.2f}\")\n",
    "print(f\"Mean Accuracy: {mean_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The 10-fold cross-validation results show a mean loss of 0.88 and a mean accuracy of 65.83%. This suggests that, on average, the model's predictions are about 65.83% correct across different subsets of the data, indicating a moderate level of predictive ability. The average loss of 0.88 points shows model's erroring instances when making predictions, where lower values would signify better performance. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
